name: SEO Audit Runner

on:
  # Allows manual triggering from the GitHub Actions tab
  workflow_dispatch:
    inputs:
      audit_url:
        description: 'The URL to audit (required)'
        required: true
        default: 'https://www.example.com/'
      audit_level:
        description: 'The SEO audit level (Basic or Standard)'
        required: true
        default: 'standard'
        type: choice
        options:
          - basic
          - standard
      audit_scope:
        description: 'The scope and depth of the audit:'
        required: true
        default: 'only_onpage'
        type: choice
          # Only crawls the initial URL provided (1 page limit)
          - only_onpage 
          # Crawls initial URL + pages found in sitemap/index (Limit 25 pages)
          - indexed_pages 
          # Deep Crawl of the site (Limit 300 pages, On-Page & Indexed included)
          - full_300_pages 
      competitor_url:
        description: 'Competitor URL for competitive analysis (optional)'
        required: false
        default: ''

jobs:
  run-audit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install system dependencies for Playwright
        # These dependencies are required on the runner for Playwright's browser
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libglib2.0-0 libnss3 libfontconfig1 libcups2 libxtst6 libxss1 libgbm-dev \
            libasound2-data libasound2-plugins libpulse0 libffi-dev libx264-dev

      - name: Install Python dependencies and corpora
        # This step uses the updated requirements.txt and installs the browser
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt --upgrade
          # Installs the web browser necessary for Scrapy-Playwright (for JS rendering)
          playwright install --with-deps
          python -m textblob.download_corpora
          python -m nltk.downloader punkt

      - name: Run SEO Audit (Handles JS pages)
        env:
          AUDIT_URL: ${{ github.event.inputs.audit_url }}
          AUDIT_LEVEL: ${{ github.event.inputs.audit_level }}
          AUDIT_SCOPE: ${{ github.event.inputs.audit_scope }}
          COMPETITOR_URL: ${{ github.event.inputs.competitor_url }}
        # The main.py script reads these environment variables
        run: python main.py

      - name: Upload SEO Audit Reports
        uses: actions/upload-artifact@v4
        with:
          name: seo-audit-reports-${{ github.event.inputs.audit_level }}-${{ github.event.inputs.audit_scope }}
          path: reports/
          
