# .github/workflows/audit.yml (FINAL & CORRECTED)
name: Professional SEO Audit

# Trigger the workflow manually with input fields
on:
  workflow_dispatch:
    inputs:
      audit_url:
        description: 'URL to audit'
        required: true
        default: # FIXED: Added a safe default URL
      audit_level:
        description: 'Audit level (basic, standard, or advanced)'
        required: true
        default: # FIXED: Added a safe default level
        type: choice
        options:
        - basic
        - standard
        - advanced
      competitor_url:
        description: 'Competitor URL for comparison (Optional)'
        required: false
      audit_scope:
        description: 'Crawl scope'
        required: true
        default: # FIXED: Added a safe default scope
        type: choice
        options:
        - only_onpage
        - onpage_and_index_pages
        - full_site_250_pages

jobs:
  run-audit:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Set up Python (VERSION FIXED) ‚úÖ
        uses: actions/setup-python@v5
        with:
          # Using '3.9' for reliable installation of Scrapy and Playwright dependencies
          python-version: '3.9' 
          
      - name: Install system dependencies for Playwright (CRITICAL FIX) ‚öôÔ∏è
        # This step installs headless browser dependencies (libglib2.0-0, libnss3, etc.)
        # that are required for Playwright to run on the Ubuntu runner.
        run: |
          sudo apt-get update
          sudo apt-get install -y libglib2.0-0 libnss3 libfontconfig1 libcups2 libxtst6 libxss1 libgbm-dev
          
      - name: Install dependencies and corpora üõ†Ô∏è
        run: |
          python -m pip install --upgrade pip
          # Ensure all Python dependencies are installed from requirements.txt
          pip install -r requirements.txt --upgrade
          # Install Playwright browser drivers required by Scrapy-Playwright
          playwright install --with-deps
          # Downloads the necessary data for textblob and textstat 
          python -m textblob.download_corpora
          
      - name: Run SEO Audit üöÄ
        env:
          AUDIT_URL: ${{ github.event.inputs.audit_url }}
          AUDIT_LEVEL: ${{ github.event.inputs.audit_level }}
          COMPETITOR_URL: ${{ github.event.inputs.competitor_url }}
          AUDIT_SCOPE: ${{ github.event.inputs.audit_scope }}
        run: |
          python main.py
          
      - name: Upload SEO Audit Reports
        uses: actions/upload-artifact@v4
        with:
          name: seo-audit-reports-${{ github.event.inputs.audit_level }}
          path: reports/
          retention-days: 5
          
