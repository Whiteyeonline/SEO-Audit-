# .github/workflows/audit.yml
name: Automated SEO Audit

# 1. Define the trigger: Manual workflow dispatch
on:
  workflow_dispatch:
    # (Inputs remain correct)
    inputs:
      audit_url:
        description: 'Target URL for the SEO audit
        required: true
        default:
      audit_level:
        description: 'Audit scope (standard or advanced)'
        required: true
        default: 'standard'
        type: choice
        options:
          - standard
          - advanced
      audit_scope:
        description: 'Crawl depth (only_onpage, indexed_pages, full_300_pages)'
        required: true
        default: 'only_onpage'
        type: choice
        options:
          - only_onpage
          - indexed_pages
          - full_300_pages
      competitor_url:
        description: 'Optional competitor URL for analysis'
        required: false

jobs:
  run_seo_audit:
    runs-on: ubuntu-latest
    
    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v4

      - name: 2. Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip' 

      # CRITICAL: Installs system dependencies for the browser executable
      - name: 3. Install Playwright system dependencies
        run: sudo apt-get update && sudo apt-get install -y libnss3 libatk1.0-0 libatk-bridge2.0-0 libcups2 libgbm-dev libxkbcommon-x11-0

      - name: 4. Install Python dependencies and Playwright browser
        run: |
          python -m pip install --upgrade pip
          # This line will now succeed with the corrected requirements.txt
          pip install -r requirements.txt
          # Installs the actual Chromium executable required by Scrapy-Playwright
          playwright install chromium --with-deps 
          # Installs NLP data for keyword and content analysis
          python -m textblob.download_corpora
          python -m nltk.downloader punkt
          
      - name: 5. Run SEO Audit (Handles JS pages)
        env:
          AUDIT_URL: ${{ github.event.inputs.audit_url }}
          AUDIT_LEVEL: ${{ github.event.inputs.audit_level }}
          AUDIT_SCOPE: ${{ github.event.inputs.audit_scope }}
          COMPETITOR_URL: ${{ github.event.inputs.competitor_url }}
        run: python main.py

      - name: 6. Upload SEO Audit Reports
        uses: actions/upload-artifact@v4
        with:
          name: seo-audit-reports-${{ github.event.inputs.audit_level }}-${{ github.event.inputs.audit_scope }}
          path: reports/
          if-no-files-found: warn 
          
